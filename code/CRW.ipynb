{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CRW.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fyVxbg1Gmjzg"},"source":["#IMPORTS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPce4tinxOyr","executionInfo":{"status":"ok","timestamp":1635561115733,"user_tz":240,"elapsed":31453,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}},"outputId":"e32109b3-3ad8-4792-90c4-1fecb9221caa"},"source":["# run\n","!pip install av\n","!pip install visdom wandb"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting av\n","  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n","\u001b[K     |████████████████████████████████| 37.2 MB 60 kB/s \n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-8.0.3\n","Collecting visdom\n","  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n","\u001b[K     |████████████████████████████████| 676 kB 5.1 MB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 52.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom) (2.23.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom) (5.1.1)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom) (22.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom) (1.15.0)\n","Collecting jsonpatch\n","  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n","Collecting torchfile\n","  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n","Collecting websocket-client\n","  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 66.7 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 70.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.1 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (1.24.3)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Collecting jsonpointer>=1.9\n","  Downloading jsonpointer-2.1-py2.py3-none-any.whl (7.4 kB)\n","Building wheels for collected packages: visdom, subprocess32, pathtools, torchfile\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=1e50f7994c426672ba6c497f7290c9f15c15d4ea95b88ab7a466390e5bda419f\n","  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=7e1d0978d5b52e5661eeb6663fe578969c0b2b9fd6a7a2cca7da1f801b06168e\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=9ca07f18a7e49dfd0d69275bf25296f0b852289028d298968c4513c8fb60529a\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5710 sha256=ad0b97949286f362cfa80828c2a6c964d47917f488261643f6de64f312c25040\n","  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n","Successfully built visdom subprocess32 pathtools torchfile\n","Installing collected packages: smmap, jsonpointer, gitdb, yaspin, websocket-client, torchfile, subprocess32, shortuuid, sentry-sdk, pathtools, jsonpatch, GitPython, docker-pycreds, configparser, wandb, visdom\n","Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 jsonpatch-1.32 jsonpointer-2.1 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 torchfile-0.1.0 visdom-0.1.8.9 wandb-0.12.6 websocket-client-1.2.1 yaspin-2.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_p0vKjzfKrr","executionInfo":{"status":"ok","timestamp":1635561183053,"user_tz":240,"elapsed":67332,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}},"outputId":"609b9f8c-72aa-40bc-a90f-a788072e1e62"},"source":["# run\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"FyL--y_wOtDx"},"source":["#LOADING DATA\n","`vos/all_frames/clips_all.zip` has all the `mp4` files from Youtube-VOS, while the frame zips have images for each video. The torchvision data loader (and CRW code) is setup to work with `mp4`. \n","\n","But `clips_all.zip` probably has train/valid/test clips. May want to filter only the train clips."]},{"cell_type":"code","metadata":{"id":"yPZBBLfGOy2K"},"source":["%%capture\n","!mkdir vos_clips\n","!unzip /content/drive/Shareddrives/EECS\\ 542/vos/all_frames/clips_all.zip -d vos_clips"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZzvU-wawuEL"},"source":["dataset = data.kinetics.Kinetics400(\"vos_clips\", frames_per_clip=8, transform=None, extensions=('mp4'), frame_rate=8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9vPQpdT8Rpc"},"source":["torch.save(dataset, \"drive/Shareddrives/EECS 542/vos_all_clips\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyrEjKZea_6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635534598622,"user_tz":240,"elapsed":8,"user":{"displayName":"Raul Dutta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05703349588025246984"}},"outputId":"872715f6-af2d-4c9d-cbe7-6dafff2aab90"},"source":["!cd videowalk"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 0: cd: videowalk: No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"1bEGpd2RbCUQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"011d6dd6-30c6-405a-e173-dc82a012e41b"},"source":["!python -W ignore \"/content/drive/Shareddrives/EECS 542/videowalk-master/code/train.py\" --data-path \"vos_clips/\" \\\n","--frame-aug grid --dropout 0.1 --clip-len 4 --temp 0.05 \\\n","--model-type scratch --workers 16 --batch-size 2  \\\n","--cache-dataset --data-parallel  --lr 0.0001 \\\n","--output-dir \"/content/drive/Shareddrives/EECS 542/data-dump/\"\n","#--visualize"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=2, cache_dataset=True, clip_len=4, clips_per_video=5, data_parallel=True, data_path='vos_clips/', device='cuda', dropout=0.1, epochs=25, fast_test=False, featdrop=0.0, flip=False, frame_aug='grid', frame_skip=8, frame_transforms='crop', head_depth=0, img_size=256, lr=0.0001, lr_gamma=0.3, lr_milestones=[20, 30, 40], lr_warmup_epochs=0, model_type='scratch', momentum=0.9, name='', optim='adam', output_dir='/content/drive/Shareddrives/EECS 542/data-dump/', partial_reload='', patch_size=[64, 64, 3], port=8095, print_freq=10, remove_layers=[], restrict=-1, resume='', server='localhost', sk_align=False, sk_targets=False, start_epoch=0, steps_per_epoch=10000000000.0, temp=0.05, visualize=False, weight_decay=0.0001, workers=16, zero_diagonal=False)\n","torch version:  1.9.0+cu111\n","torchvision version:  0.10.0+cu111\n","Preparing training dataloader\n","Frame transforms: [RandomResizedCrop(size=(256, 256), scale=(0.8, 0.95), ratio=(0.7, 1.3), interpolation=bilinear)] crop\n","Frame augs: Compose(\n","    ToTensor()\n","    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",") grid\n","!!!\n","Loading dataset_train from drive/Shareddrives/EECS 542/vos_all_clips\n","['clips']\n","{'clips': 0}\n","Took 0.6085927486419678\n","Creating data loaders\n","Creating model\n","stride Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","padding Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","CRW(\n","  (encoder): From3D(\n","    (model): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False, padding_mode=reflect)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): None\n","      (fc): None\n","    )\n","  )\n","  (selfsim_fc): Sequential(\n","    (0): Linear(in_features=512, out_features=128, bias=True)\n","  )\n","  (xent): CrossEntropyLoss()\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (featdrop): Dropout(p=0.0, inplace=False)\n",")\n","Start training\n","Epoch: [0]  [   0/6510]  eta: 1 day, 12:09:31  lr: 0.0001  clips/s: 0.342  loss: 3.7924 (3.7924)  time: 19.9956  data: 14.1420  max mem: 4766\n","Epoch: [0]  [  10/6510]  eta: 5:13:07  lr: 0.0001  clips/s: 3.067  loss: 2.7298 (2.8279)  time: 2.8905  data: 1.2893  max mem: 4766\n","Epoch: [0]  [  20/6510]  eta: 3:17:55  lr: 0.0001  clips/s: 3.040  loss: 2.6623 (2.7478)  time: 0.9216  data: 0.0035  max mem: 4766\n","Epoch: [0]  [  30/6510]  eta: 2:55:27  lr: 0.0001  clips/s: 3.057  loss: 2.4753 (2.6347)  time: 0.9284  data: 0.2689  max mem: 4766\n","Epoch: [0]  [  40/6510]  eta: 2:46:53  lr: 0.0001  clips/s: 3.095  loss: 2.4204 (2.5888)  time: 1.2514  data: 0.5888  max mem: 4766\n","Epoch: [0]  [  50/6510]  eta: 2:35:44  lr: 0.0001  clips/s: 3.022  loss: 2.2422 (2.5304)  time: 1.1704  data: 0.5075  max mem: 4766\n","Epoch: [0]  [  60/6510]  eta: 2:27:38  lr: 0.0001  clips/s: 2.909  loss: 2.1143 (2.4579)  time: 1.0160  data: 0.3578  max mem: 4766\n","Epoch: [0]  [  70/6510]  eta: 2:26:59  lr: 0.0001  clips/s: 3.037  loss: 2.1971 (2.4717)  time: 1.1734  data: 0.5108  max mem: 4766\n","Epoch: [0]  [  80/6510]  eta: 2:25:02  lr: 0.0001  clips/s: 2.976  loss: 2.3467 (2.4577)  time: 1.2927  data: 0.6221  max mem: 4766\n","Epoch: [0]  [  90/6510]  eta: 2:20:51  lr: 0.0001  clips/s: 3.058  loss: 2.3467 (2.4421)  time: 1.1279  data: 0.4607  max mem: 4766\n","Epoch: [0]  [ 100/6510]  eta: 2:18:53  lr: 0.0001  clips/s: 3.058  loss: 2.1434 (2.4034)  time: 1.0842  data: 0.4221  max mem: 4766\n","Epoch: [0]  [ 110/6510]  eta: 2:18:23  lr: 0.0001  clips/s: 3.135  loss: 2.1088 (2.3778)  time: 1.2105  data: 0.4013  max mem: 4766\n","Epoch: [0]  [ 120/6510]  eta: 2:18:30  lr: 0.0001  clips/s: 3.015  loss: 2.1310 (2.3541)  time: 1.3027  data: 0.4853  max mem: 4766\n","Epoch: [0]  [ 130/6510]  eta: 2:17:41  lr: 0.0001  clips/s: 3.094  loss: 2.1310 (2.3445)  time: 1.2809  data: 0.6114  max mem: 4766\n","Epoch: [0]  [ 140/6510]  eta: 2:16:07  lr: 0.0001  clips/s: 3.092  loss: 2.0861 (2.3255)  time: 1.1713  data: 0.5145  max mem: 4766\n","Epoch: [0]  [ 150/6510]  eta: 2:12:27  lr: 0.0001  clips/s: 3.001  loss: 2.0858 (2.3123)  time: 0.9531  data: 0.2980  max mem: 4766\n","Epoch: [0]  [ 160/6510]  eta: 2:15:20  lr: 0.0001  clips/s: 3.095  loss: 2.1251 (2.3031)  time: 1.2542  data: 0.5934  max mem: 4766\n","Epoch: [0]  [ 170/6510]  eta: 2:13:43  lr: 0.0001  clips/s: 3.049  loss: 2.0608 (2.2901)  time: 1.3855  data: 0.7258  max mem: 4766\n","Epoch: [0]  [ 180/6510]  eta: 2:11:14  lr: 0.0001  clips/s: 3.129  loss: 2.1265 (2.2859)  time: 0.9640  data: 0.3107  max mem: 4766\n","Epoch: [0]  [ 190/6510]  eta: 2:13:18  lr: 0.0001  clips/s: 2.930  loss: 2.0979 (2.2774)  time: 1.2673  data: 0.6144  max mem: 4766\n","Epoch: [0]  [ 200/6510]  eta: 2:12:19  lr: 0.0001  clips/s: 3.114  loss: 2.0907 (2.2743)  time: 1.3872  data: 0.7300  max mem: 4766\n","Epoch: [0]  [ 210/6510]  eta: 2:12:23  lr: 0.0001  clips/s: 2.903  loss: 2.1223 (2.2683)  time: 1.2157  data: 0.3273  max mem: 4766\n"]}]},{"cell_type":"code","metadata":{"id":"lLKdPOUFuy_2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635354633597,"user_tz":240,"elapsed":547,"user":{"displayName":"Nameer Hirschkind","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07136431999205915963"}},"outputId":"34a96fa3-8470-417b-ab58-26514b768e9f"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Oct 27 17:10:33 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"nUZB6EoGfcpg"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"uwtMFqcRgSCd","executionInfo":{"status":"ok","timestamp":1635563132449,"user_tz":240,"elapsed":12766,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["%%capture\n","!mkdir davis\n","!unzip /content/drive/Shareddrives/EECS\\ 542/DAVIS-2017-trainval-480p.zip"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkbtKYDl-UOZ","executionInfo":{"status":"ok","timestamp":1635563132452,"user_tz":240,"elapsed":18,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["!mv DAVIS/* davis/"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"89CFGp8w4wB4"},"source":["!zip -r davis2017_trainval.zip /content/davis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6egQHy295tNn","executionInfo":{"status":"ok","timestamp":1635542048273,"user_tz":240,"elapsed":3484,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["!cp davis2017_trainval.zip /content/drive/Shareddrives/EECS\\ 542/"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"xa8Y_nFL0tYb","executionInfo":{"status":"ok","timestamp":1635561393030,"user_tz":240,"elapsed":62241,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["!cp -r /content/drive/Shareddrives/EECS\\ 542/data-dump .\n","!cp -r /content/drive/Shareddrives/EECS\\ 542/videowalk-master/ ."],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SEjAREGj0aS","executionInfo":{"status":"ok","timestamp":1635563233777,"user_tz":240,"elapsed":374,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["#PRETRAINED_PATH = \"data-dump/model_4_201.pth\"\n","PRETRAINED_PATH = \"videowalk-master/pretrained.pth\"\n","TEST_PY = \"videowalk-master/code/test.py\"\n","\n","\n","DAVIS_FILE_PATH = \"davis_vallist.txt\""],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvtKHXNbfi-0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635564555636,"user_tz":240,"elapsed":202316,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}},"outputId":"8c4cb4e9-2377-4199-aaba-ec18b4863b55"},"source":["!python $TEST_PY --filelist $DAVIS_FILE_PATH \\\n","    --model-type scratch --resume $PRETRAINED_PATH --save-path /content/davis_results5 \\\n","    --topk 10 --videoLen 20 --radius 12  --temperature 0.05 --cropSize 256"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU 0\n","Context Length: 20 Image Size: 256\n","Arguments Namespace(batchSize=1, cropSize=256, device='cuda', filelist='davis_vallist.txt', finetune=0, gpu_id='0', head_depth=-1, imgSize=256, long_mem=[0], manualSeed=777, model_type='scratch', no_l2=False, norm_mask=False, pca_vis=False, radius=12.0, remove_layers=['layer4'], resume='videowalk-master/pretrained.pth', round=False, save_path='/content/davis_results5', temperature=0.05, texture=False, topk=10, videoLen=20, visdom=False, visdom_server='localhost', workers=4)\n","stride Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","padding Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","padding Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","stride Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Total params: 2.78M\n","==> Resuming from checkpoint..\n","\n","Skipped keys:  ['encoder.model.layer4.0.conv1.weight', 'encoder.model.layer4.0.bn1.weight', 'encoder.model.layer4.0.bn1.bias', 'encoder.model.layer4.0.bn1.running_mean', 'encoder.model.layer4.0.bn1.running_var', 'encoder.model.layer4.0.bn1.num_batches_tracked', 'encoder.model.layer4.0.conv2.weight', 'encoder.model.layer4.0.bn2.weight', 'encoder.model.layer4.0.bn2.bias', 'encoder.model.layer4.0.bn2.running_mean', 'encoder.model.layer4.0.bn2.running_var', 'encoder.model.layer4.0.bn2.num_batches_tracked', 'encoder.model.layer4.0.downsample.0.weight', 'encoder.model.layer4.0.downsample.1.weight', 'encoder.model.layer4.0.downsample.1.bias', 'encoder.model.layer4.0.downsample.1.running_mean', 'encoder.model.layer4.0.downsample.1.running_var', 'encoder.model.layer4.0.downsample.1.num_batches_tracked', 'encoder.model.layer4.1.conv1.weight', 'encoder.model.layer4.1.bn1.weight', 'encoder.model.layer4.1.bn1.bias', 'encoder.model.layer4.1.bn1.running_mean', 'encoder.model.layer4.1.bn1.running_var', 'encoder.model.layer4.1.bn1.num_batches_tracked', 'encoder.model.layer4.1.conv2.weight', 'encoder.model.layer4.1.bn2.weight', 'encoder.model.layer4.1.bn2.bias', 'encoder.model.layer4.1.bn2.running_mean', 'encoder.model.layer4.1.bn2.running_var', 'encoder.model.layer4.1.bn2.num_batches_tracked', 'selfsim_fc.0.weight', 'selfsim_fc.0.bias']\n","\n","Loading keys:  dict_keys(['encoder.model.conv1.weight', 'encoder.model.bn1.weight', 'encoder.model.bn1.bias', 'encoder.model.bn1.running_mean', 'encoder.model.bn1.running_var', 'encoder.model.bn1.num_batches_tracked', 'encoder.model.layer1.0.conv1.weight', 'encoder.model.layer1.0.bn1.weight', 'encoder.model.layer1.0.bn1.bias', 'encoder.model.layer1.0.bn1.running_mean', 'encoder.model.layer1.0.bn1.running_var', 'encoder.model.layer1.0.bn1.num_batches_tracked', 'encoder.model.layer1.0.conv2.weight', 'encoder.model.layer1.0.bn2.weight', 'encoder.model.layer1.0.bn2.bias', 'encoder.model.layer1.0.bn2.running_mean', 'encoder.model.layer1.0.bn2.running_var', 'encoder.model.layer1.0.bn2.num_batches_tracked', 'encoder.model.layer1.1.conv1.weight', 'encoder.model.layer1.1.bn1.weight', 'encoder.model.layer1.1.bn1.bias', 'encoder.model.layer1.1.bn1.running_mean', 'encoder.model.layer1.1.bn1.running_var', 'encoder.model.layer1.1.bn1.num_batches_tracked', 'encoder.model.layer1.1.conv2.weight', 'encoder.model.layer1.1.bn2.weight', 'encoder.model.layer1.1.bn2.bias', 'encoder.model.layer1.1.bn2.running_mean', 'encoder.model.layer1.1.bn2.running_var', 'encoder.model.layer1.1.bn2.num_batches_tracked', 'encoder.model.layer2.0.conv1.weight', 'encoder.model.layer2.0.bn1.weight', 'encoder.model.layer2.0.bn1.bias', 'encoder.model.layer2.0.bn1.running_mean', 'encoder.model.layer2.0.bn1.running_var', 'encoder.model.layer2.0.bn1.num_batches_tracked', 'encoder.model.layer2.0.conv2.weight', 'encoder.model.layer2.0.bn2.weight', 'encoder.model.layer2.0.bn2.bias', 'encoder.model.layer2.0.bn2.running_mean', 'encoder.model.layer2.0.bn2.running_var', 'encoder.model.layer2.0.bn2.num_batches_tracked', 'encoder.model.layer2.0.downsample.0.weight', 'encoder.model.layer2.0.downsample.1.weight', 'encoder.model.layer2.0.downsample.1.bias', 'encoder.model.layer2.0.downsample.1.running_mean', 'encoder.model.layer2.0.downsample.1.running_var', 'encoder.model.layer2.0.downsample.1.num_batches_tracked', 'encoder.model.layer2.1.conv1.weight', 'encoder.model.layer2.1.bn1.weight', 'encoder.model.layer2.1.bn1.bias', 'encoder.model.layer2.1.bn1.running_mean', 'encoder.model.layer2.1.bn1.running_var', 'encoder.model.layer2.1.bn1.num_batches_tracked', 'encoder.model.layer2.1.conv2.weight', 'encoder.model.layer2.1.bn2.weight', 'encoder.model.layer2.1.bn2.bias', 'encoder.model.layer2.1.bn2.running_mean', 'encoder.model.layer2.1.bn2.running_var', 'encoder.model.layer2.1.bn2.num_batches_tracked', 'encoder.model.layer3.0.conv1.weight', 'encoder.model.layer3.0.bn1.weight', 'encoder.model.layer3.0.bn1.bias', 'encoder.model.layer3.0.bn1.running_mean', 'encoder.model.layer3.0.bn1.running_var', 'encoder.model.layer3.0.bn1.num_batches_tracked', 'encoder.model.layer3.0.conv2.weight', 'encoder.model.layer3.0.bn2.weight', 'encoder.model.layer3.0.bn2.bias', 'encoder.model.layer3.0.bn2.running_mean', 'encoder.model.layer3.0.bn2.running_var', 'encoder.model.layer3.0.bn2.num_batches_tracked', 'encoder.model.layer3.0.downsample.0.weight', 'encoder.model.layer3.0.downsample.1.weight', 'encoder.model.layer3.0.downsample.1.bias', 'encoder.model.layer3.0.downsample.1.running_mean', 'encoder.model.layer3.0.downsample.1.running_var', 'encoder.model.layer3.0.downsample.1.num_batches_tracked', 'encoder.model.layer3.1.conv1.weight', 'encoder.model.layer3.1.bn1.weight', 'encoder.model.layer3.1.bn1.bias', 'encoder.model.layer3.1.bn1.running_mean', 'encoder.model.layer3.1.bn1.running_var', 'encoder.model.layer3.1.bn1.num_batches_tracked', 'encoder.model.layer3.1.conv2.weight', 'encoder.model.layer3.1.bn2.weight', 'encoder.model.layer3.1.bn2.bias', 'encoder.model.layer3.1.bn2.running_mean', 'encoder.model.layer3.1.bn2.running_var', 'encoder.model.layer3.1.bn2.num_batches_tracked'])\n","******* Vid 0 (89 frames) *******\n","computed features 0.8313939571380615\n","tcmalloc: large alloc 1519386624 bytes == 0x55d44ac98000 @  0x7f124a101b6b 0x7f124a121379 0x7f11924d926e 0x7f11924da9e2 0x7f1193855e19 0x7f1193856b67 0x7f1193c33059 0x7f1194397e6a 0x7f119437af8e 0x7f1193f7fcd5 0x7f119383f0fe 0x7f1193840acb 0x7f1193841f03 0x7f1193c1b9a6 0x7f1193c1f354 0x7f1194398a6f 0x7f119425282e 0x7f11959a98c5 0x7f11959a9d72 0x7f11946b1835 0x7f123732edf2 0x55d3c0fee409 0x55d3c0f75e7a 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f749ee 0x55d3c0f746f3 0x55d3c103e4c2 0x55d3c103e83d\n","computing affinity\n","6.340656042098999 affinity forward, max mem 817.37548828125\n","******* Vid 0 TOOK 13.27037787437439 *******\n","******* Vid 1 (70 frames) *******\n","computed features 0.3784210681915283\n","computing affinity\n","2.6295242309570312 affinity forward, max mem 817.37548828125\n","******* Vid 1 TOOK 5.354325294494629 *******\n","******* Vid 2 (100 frames) *******\n","computed features 0.4418327808380127\n","tcmalloc: large alloc 1761607680 bytes == 0x55d4f491c000 @  0x7f124a101b6b 0x7f124a121379 0x7f11924d926e 0x7f11924da9e2 0x7f1193855e19 0x7f1193856b67 0x7f1193c33059 0x7f1194397e6a 0x7f119437af8e 0x7f1193f7fcd5 0x7f119383f0fe 0x7f1193840acb 0x7f1193841f03 0x7f1193c1b9a6 0x7f1193c1f354 0x7f1194398a6f 0x7f119425282e 0x7f11959a98c5 0x7f11959a9d72 0x7f11946b1835 0x7f123732edf2 0x55d3c0fee409 0x55d3c0f75e7a 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f749ee 0x55d3c0f746f3 0x55d3c103e4c2 0x55d3c103e83d\n","computing affinity\n","4.216263771057129 affinity forward, max mem 817.37548828125\n","******* Vid 2 TOOK 9.419907808303833 *******\n","******* Vid 3 (104 frames) *******\n","computed features 0.7656757831573486\n","tcmalloc: large alloc 1849688064 bytes == 0x55d55d91c000 @  0x7f124a101b6b 0x7f124a121379 0x7f11924d926e 0x7f11924da9e2 0x7f1193855e19 0x7f1193856b67 0x7f1193c33059 0x7f1194397e6a 0x7f119437af8e 0x7f1193f7fcd5 0x7f119383f0fe 0x7f1193840acb 0x7f1193841f03 0x7f1193c1b9a6 0x7f1193c1f354 0x7f1194398a6f 0x7f119425282e 0x7f11959a98c5 0x7f11959a9d72 0x7f11946b1835 0x7f123732edf2 0x55d3c0fee409 0x55d3c0f75e7a 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f749ee 0x55d3c0f746f3 0x55d3c103e4c2 0x55d3c103e83d\n","computing affinity\n","6.295275926589966 affinity forward, max mem 817.37548828125\n","******* Vid 3 TOOK 11.219476222991943 *******\n","******* Vid 4 (110 frames) *******\n","computed features 0.5442192554473877\n","tcmalloc: large alloc 1981808640 bytes == 0x55d5cbd1c000 @  0x7f124a101b6b 0x7f124a121379 0x7f11924d926e 0x7f11924da9e2 0x7f1193855e19 0x7f1193856b67 0x7f1193c33059 0x7f1194397e6a 0x7f119437af8e 0x7f1193f7fcd5 0x7f119383f0fe 0x7f1193840acb 0x7f1193841f03 0x7f1193c1b9a6 0x7f1193c1f354 0x7f1194398a6f 0x7f119425282e 0x7f11959a98c5 0x7f11959a9d72 0x7f11946b1835 0x7f123732edf2 0x55d3c0fee409 0x55d3c0f75e7a 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f749ee 0x55d3c0f746f3 0x55d3c103e4c2 0x55d3c103e83d\n","computing affinity\n","4.920823812484741 affinity forward, max mem 817.37548828125\n","******* Vid 4 TOOK 9.767509698867798 *******\n","******* Vid 5 (95 frames) *******\n","computed features 0.4639320373535156\n","computing affinity\n","3.7335660457611084 affinity forward, max mem 817.37548828125\n","******* Vid 5 TOOK 8.250412464141846 *******\n","******* Vid 6 (60 frames) *******\n","computed features 0.2907371520996094\n","computing affinity\n","2.3320159912109375 affinity forward, max mem 817.37548828125\n","******* Vid 6 TOOK 4.032760381698608 *******\n","******* Vid 7 (124 frames) *******\n","computed features 0.6111793518066406\n","tcmalloc: large alloc 2290089984 bytes == 0x55d4f491c000 @  0x7f124a101b6b 0x7f124a121379 0x7f11924d926e 0x7f11924da9e2 0x7f1193855e19 0x7f1193856b67 0x7f1193c33059 0x7f1194397e6a 0x7f119437af8e 0x7f1193f7fcd5 0x7f119383f0fe 0x7f1193840acb 0x7f1193841f03 0x7f1193c1b9a6 0x7f1193c1f354 0x7f1194398a6f 0x7f119425282e 0x7f11959a98c5 0x7f11959a9d72 0x7f11946b1835 0x7f123732edf2 0x55d3c0fee409 0x55d3c0f75e7a 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f749ee 0x55d3c0f746f3 0x55d3c103e4c2 0x55d3c103e83d\n","computing affinity\n","5.18266749382019 affinity forward, max mem 817.37548828125\n","******* Vid 7 TOOK 11.030648708343506 *******\n","******* Vid 8 (110 frames) *******\n","computed features 0.6071395874023438\n","tcmalloc: large alloc 1981808640 bytes == 0x55d57d11c000 @  0x7f124a101b6b 0x7f124a121379 0x7f11924d926e 0x7f11924da9e2 0x7f1193855e19 0x7f1193856b67 0x7f1193c33059 0x7f1194397e6a 0x7f119437af8e 0x7f1193f7fcd5 0x7f119383f0fe 0x7f1193840acb 0x7f1193841f03 0x7f1193c1b9a6 0x7f1193c1f354 0x7f1194398a6f 0x7f119425282e 0x7f11959a98c5 0x7f11959a9d72 0x7f11946b1835 0x7f123732edf2 0x55d3c0fee409 0x55d3c0f75e7a 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f07afa 0x55d3c0f75915 0x55d3c0f749ee 0x55d3c0f746f3 0x55d3c103e4c2 0x55d3c103e83d\n","computing affinity\n","4.9853739738464355 affinity forward, max mem 817.37548828125\n","******* Vid 8 TOOK 9.261090278625488 *******\n","******* Vid 9 (80 frames) *******\n","computed features 0.418287992477417\n","computing affinity\n","3.2606043815612793 affinity forward, max mem 817.37548828125\n","******* Vid 9 TOOK 6.110762119293213 *******\n","******* Vid 10 (86 frames) *******\n","computed features 0.4371628761291504\n","computing affinity\n","3.7618720531463623 affinity forward, max mem 817.37548828125\n","******* Vid 10 TOOK 7.810669183731079 *******\n","******* Vid 11 (72 frames) *******\n","computed features 0.6005845069885254\n","computing affinity\n","2.899327039718628 affinity forward, max mem 817.37548828125\n","******* Vid 11 TOOK 4.528535842895508 *******\n","******* Vid 12 (70 frames) *******\n","computed features 0.2991909980773926\n","computing affinity\n","2.6377298831939697 affinity forward, max mem 817.37548828125\n","******* Vid 12 TOOK 4.170851469039917 *******\n","******* Vid 13 (110 frames) *******\n","computed features 0.5560758113861084\n","^C\n"]}]},{"cell_type":"code","metadata":{"id":"DQDXCj_Lfw3v","executionInfo":{"status":"ok","timestamp":1635564682302,"user_tz":240,"elapsed":126672,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["# Convert\n","!python videowalk-master/code/eval/convert_davis.py \\\n","     --in_folder davis_results5/ --out_folder davis_final5/ --dataset /content/davis"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZraahEw3H8ai","executionInfo":{"status":"ok","timestamp":1635564683796,"user_tz":240,"elapsed":1504,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}},"outputId":"e77eb7ca-8265-4256-a915-e7203cf32fad"},"source":["# Compute metrics\n","!python davis2017-evaluation/evaluation_method.py \\\n","--task semi-supervised   --results_path davis_final5/ --set val \\\n","--davis_path davis/"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Using precomputed results...\n","--------------------------- Global results for val ---------------------------\n"," J&F-Mean  J-Mean  J-Recall  J-Decay  F-Mean  F-Recall  F-Decay\n","    0.474   0.478     0.544    0.208   0.469     0.527    0.241\n","\n","---------- Per sequence results for val ----------\n","             Sequence  J-Mean  F-Mean\n","       bike-packing_1   0.391   0.584\n","       bike-packing_2   0.531   0.618\n","          blackswan_1   0.852   0.862\n","          bmx-trees_1   0.072   0.181\n","          bmx-trees_2   0.415   0.590\n","         breakdance_1   0.532   0.482\n","              camel_1   0.606   0.494\n","     car-roundabout_1   0.868   0.749\n","         car-shadow_1   0.784   0.738\n","               cows_1   0.809   0.671\n","        dance-twirl_1   0.276   0.336\n","                dog_1   0.825   0.751\n","          dogs-jump_1   0.162   0.219\n","          dogs-jump_2   0.425   0.357\n","          dogs-jump_3   0.572   0.619\n","      drift-chicane_1   0.603   0.586\n","     drift-straight_1   0.546   0.439\n","               goat_1   0.725   0.570\n","          gold-fish_1   0.530   0.432\n","          gold-fish_2   0.513   0.520\n","          gold-fish_3   0.725   0.680\n","          gold-fish_4   0.669   0.603\n","          gold-fish_5   0.745   0.580\n","     horsejump-high_1   0.591   0.622\n","     horsejump-high_2   0.451   0.684\n","              india_1   0.752   0.613\n","              india_2   0.451   0.349\n","              india_3   0.503   0.429\n","               judo_1   0.532   0.533\n","               judo_2   0.384   0.399\n","          kite-surf_1   0.135   0.155\n","          kite-surf_2   0.250   0.250\n","          kite-surf_3   0.464   0.737\n","           lab-coat_1   0.000   0.000\n","           lab-coat_2   0.000   0.000\n","           lab-coat_3   0.574   0.357\n","           lab-coat_4   0.416   0.315\n","           lab-coat_5   0.690   0.541\n","              libby_1   0.532   0.612\n","            loading_1   0.822   0.606\n","            loading_2   0.256   0.442\n","            loading_3   0.573   0.552\n","        mbike-trick_1   0.298   0.480\n","        mbike-trick_2   0.586   0.531\n","     motocross-jump_1   0.475   0.426\n","     motocross-jump_2   0.335   0.319\n"," paragliding-launch_1   0.749   0.812\n"," paragliding-launch_2   0.450   0.691\n"," paragliding-launch_3   0.000   0.003\n","            parkour_1   0.198   0.174\n","               pigs_1   0.567   0.444\n","               pigs_2   0.420   0.466\n","               pigs_3   0.823   0.666\n","      scooter-black_1   0.066   0.203\n","      scooter-black_2   0.637   0.507\n","           shooting_1   0.279   0.293\n","           shooting_2   0.605   0.449\n","           shooting_3   0.408   0.512\n","            soapbox_1   0.561   0.483\n","            soapbox_2   0.137   0.214\n","            soapbox_3   0.040   0.085\n","\n","Total time:0.01636362075805664"]}]},{"cell_type":"code","metadata":{"id":"nuDeRdORO7Xj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAZpMadMVcf_","executionInfo":{"status":"ok","timestamp":1635548646672,"user_tz":240,"elapsed":1200,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}},"outputId":"531b986b-5721-4070-bce6-f19ab92a4135"},"source":["# pretrained results\n","!python davis2017-evaluation/evaluation_method.py \\\n","--task semi-supervised   --results_path davis_final2/ --set val \\\n","--davis_path davis/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using precomputed results...\n","--------------------------- Global results for val ---------------------------\n"," J&F-Mean  J-Mean  J-Recall  J-Decay  F-Mean  F-Recall  F-Decay\n","    0.172   0.188     0.184     0.24   0.156     0.109    0.235\n","\n","---------- Per sequence results for val ----------\n","             Sequence  J-Mean  F-Mean\n","       bike-packing_1   0.000   0.000\n","       bike-packing_2   0.000   0.000\n","          blackswan_1   0.000   0.000\n","          bmx-trees_1   0.000   0.000\n","          bmx-trees_2   0.000   0.000\n","         breakdance_1   0.000   0.000\n","              camel_1   0.000   0.000\n","     car-roundabout_1   0.000   0.000\n","         car-shadow_1   0.000   0.000\n","               cows_1   0.000   0.000\n","        dance-twirl_1   0.047   0.048\n","                dog_1   0.622   0.388\n","          dogs-jump_1   0.066   0.100\n","          dogs-jump_2   0.099   0.096\n","          dogs-jump_3   0.539   0.601\n","      drift-chicane_1   0.019   0.032\n","     drift-straight_1   0.230   0.162\n","               goat_1   0.197   0.132\n","          gold-fish_1   0.331   0.213\n","          gold-fish_2   0.338   0.309\n","          gold-fish_3   0.378   0.319\n","          gold-fish_4   0.260   0.212\n","          gold-fish_5   0.572   0.303\n","     horsejump-high_1   0.085   0.099\n","     horsejump-high_2   0.022   0.046\n","              india_1   0.560   0.418\n","              india_2   0.449   0.347\n","              india_3   0.347   0.256\n","               judo_1   0.535   0.466\n","               judo_2   0.336   0.314\n","          kite-surf_1   0.025   0.015\n","          kite-surf_2   0.250   0.250\n","          kite-surf_3   0.141   0.203\n","           lab-coat_1   0.000   0.000\n","           lab-coat_2   0.000   0.000\n","           lab-coat_3   0.474   0.276\n","           lab-coat_4   0.505   0.282\n","           lab-coat_5   0.208   0.199\n","              libby_1   0.203   0.184\n","            loading_1   0.601   0.296\n","            loading_2   0.121   0.150\n","            loading_3   0.396   0.336\n","        mbike-trick_1   0.010   0.045\n","        mbike-trick_2   0.075   0.102\n","     motocross-jump_1   0.017   0.030\n","     motocross-jump_2   0.027   0.029\n"," paragliding-launch_1   0.483   0.454\n"," paragliding-launch_2   0.049   0.107\n"," paragliding-launch_3   0.000   0.000\n","            parkour_1   0.023   0.030\n","               pigs_1   0.225   0.122\n","               pigs_2   0.313   0.258\n","               pigs_3   0.676   0.442\n","      scooter-black_1   0.002   0.015\n","      scooter-black_2   0.094   0.142\n","           shooting_1   0.075   0.117\n","           shooting_2   0.260   0.208\n","           shooting_3   0.090   0.226\n","            soapbox_1   0.059   0.077\n","            soapbox_2   0.042   0.079\n","            soapbox_3   0.001   0.003\n","\n","Total time:0.016341447830200195"]}]},{"cell_type":"code","metadata":{"id":"VbU_H_5AMaDb","executionInfo":{"status":"ok","timestamp":1635562244813,"user_tz":240,"elapsed":762288,"user":{"displayName":"Jack W","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09956343150821300977"}}},"source":["!cp -r /content/drive/Shareddrives/EECS\\ 542/davis2017-evaluation ."],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-o5e_3tjD6a7"},"source":[""],"execution_count":null,"outputs":[]}]}